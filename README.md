# Projets de R√©seaux de Neurones : Applications PMC et CNN

Ce d√©p√¥t pr√©sente deux projets distincts d'apprentissage automatique d√©montrant l'application et l'optimisation de r√©seaux de neurones pour des t√¢ches de classification sur des donn√©es tabulaires et des images.

**Technologies et Biblioth√®ques :**
*   **Langage :** Python
*   **Analyse de Donn√©es :** Pandas, NumPy
*   **Machine Learning :** Scikit-Learn
*   **Deep Learning :** TensorFlow, Keras
*   **Visualisation :** Matplotlib

---

## üìÇ Structure du D√©p√¥t


---

## üìà Projet 1 : Pr√©diction de Revenu Client avec un Perceptron Multi-Couches (PMC)

### Objectif du Projet
L'objectif de ce projet √©tait de construire un mod√®le pr√©dictif capable de classifier les clients en diff√©rentes cat√©gories de revenus (faible, moyen, √©lev√©) √† partir de leurs donn√©es comportementales. Ce type de mod√®le est essentiel pour des applications commerciales comme le ciblage marketing ou la segmentation client.

### D√©marche et Techniques Mises en ≈íuvre

1.  **Pr√©traitement des Donn√©es :** Nettoyage, gestion des valeurs manquantes et encodage des variables cat√©gorielles (ex: `gender`, `country`) pour pr√©parer les donn√©es pour le mod√®le.
2.  **Ing√©nierie des Caract√©ristiques :** Cr√©ation de variables cibles pour des probl√®mes de **classification binaire** (revenu sup√©rieur √† la moyenne ou non) et **multi-classes** (revenu faible, moyen, √©lev√© bas√© sur les quartiles).
3.  **Entra√Ænement du Mod√®le :** Utilisation de la classe `MLPClassifier` de Scikit-Learn pour entra√Æner les deux types de classifieurs.
4.  **Optimisation des Hyperparam√®tres :** Recherche de la meilleure architecture de r√©seau de neurones (nombre de couches, nombre de neurones) et des meilleurs param√®tres d'entra√Ænement (fonction d'activation, solveur) √† l'aide de `RandomizedSearchCV` pour une optimisation efficace.
5.  **√âvaluation et Analyse :**
    *   Utilisation de la **validation crois√©e** pour garantir la robustesse du mod√®le.
    *   Analyse des performances via des m√©triques cl√©s (**pr√©cision, rappel, F1-score**) et des **matrices de confusion**.
    *   G√©n√©ration de **courbes d'apprentissage** pour diagnostiquer le sur-ajustement et s'assurer que le mod√®le g√©n√©ralise bien.

### R√©sultats
Le PMC optimis√© a montr√© des performances nettement sup√©rieures √† un mod√®le de base (Arbre de D√©cision), avec une pr√©cision de **70%** et un F1-score pond√©r√© de **0.70** dans la t√¢che multi-classes. Contrairement √† l'arbre, le PMC a r√©ussi √† pr√©dire de mani√®re √©quilibr√©e toutes les classes de revenus, y compris les minoritaires.

---

## üñºÔ∏è Projet 2 : Classification d'Images avec des R√©seaux de Neurones √† Convolution (CNN)

### Objectif du Projet
Ce projet explore la construction et la comparaison de plusieurs architectures de deep learning pour la classification d'images sur le jeu de donn√©es **Fashion-MNIST**. L'objectif √©tait de comparer l'efficacit√© de diff√©rentes approches, de la plus simple √† la plus avanc√©e.

### Mod√®les D√©velopp√©s et Techniques Explor√©es

1.  **Mod√®le de R√©f√©rence (PMC) :** Un Perceptron Multi-Couches de base a √©t√© impl√©ment√© avec Keras pour √©tablir une performance de r√©f√©rence.
2.  **CNN Personnalis√© :** Conception et entra√Ænement d'un R√©seau de Neurones √† Convolution (CNN) incluant des couches de convolution, de pooling, de normalisation par lots (`BatchNormalization`) et de r√©gularisation (`Dropout`).
3.  **CNN avec Augmentation de Donn√©es :** Pour am√©liorer la g√©n√©ralisation et r√©duire le sur-apprentissage, la technique d'augmentation de donn√©es a √©t√© appliqu√©e en utilisant `ImageDataGenerator` de Keras, cr√©ant ainsi des variations synth√©tiques des images d'entra√Ænement (rotations, zooms, d√©calages).
4.  **Apprentissage par Transfert (Transfer Learning) :** Utilisation du mod√®le pr√©-entra√Æn√© **VGG16** comme extracteur de caract√©ristiques fixes, en y ajoutant des couches denses personnalis√©es pour la classification finale.

### Analyse Comparative des Performances

| Mod√®le | Exactitude (Test) | Temps d'entra√Ænement (sec) | Analyse |
| :--- | :---: | :---: | :--- |
| PMC (Keras) | 88.86% | 161 | Rapide mais moins performant que les architectures CNN. |
| **CNN Personnalis√©** | **93.12%** | 2631 | **Excellent √©quilibre entre une haute pr√©cision et un temps d'entra√Ænement raisonnable.** |
| CNN + Augmentation | 91.37% | 2994 | A r√©duit le sur-apprentissage mais a l√©g√®rement diminu√© la pr√©cision finale. |
| VGG16 (Transfert) | 87.61% | 14458 | Le mod√®le le plus long √† entra√Æner, probablement surdimensionn√© pour la complexit√© de Fashion-MNIST. |

### Conclusion du Projet
Le **CNN personnalis√©** s'est r√©v√©l√© √™tre l'approche la plus efficace pour ce probl√®me, offrant la meilleure pr√©cision tout en restant efficient en termes de temps de calcul.

---

## üöÄ Comment Ex√©cuter

### Pr√©requis
*   Python 3.8+
*   Jupyter Notebook ou un IDE compatible (ex: VS Code)

### Installation
1.  Clonez le d√©p√¥t sur votre machine locale :
    ```bash
    git clone [URL_DU_DEPOT]
    cd [NOM_DU_DEPOT]
    ```
2.  Il est recommand√© de cr√©er un environnement virtuel :
    ```bash
    python -m venv env
    source env/bin/activate  # Sur Windows: env\Scripts\activate
    ```
3.  Installez les biblioth√®ques n√©cessaires :
    ```bash
    pip install pandas numpy scikit-learn matplotlib tensorflow
    ```

### Lancement
1.  D√©marrez le serveur Jupyter :
    ```bash
    jupyter notebook
    ```
2.  Ouvrez et ex√©cutez les notebooks situ√©s dans leurs dossiers respectifs :
    *   `Projet_1_PMC_Prediction_Revenu/ReseauxN_Partie1_PMC.ipynb`
    *   `Projet_2_CNN_Classification_Image/ReseauxN_Partie2_CNN.ipynb`
